{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results CartPole "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import requests\n",
    "import time\n",
    "import pygame\n",
    "import re\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM API details (Modify if needed)\n",
    "LLM_API_URL = \"http://localhost:1234/v1/chat/completions\"  # Change to your LM Studio API URL  \n",
    "#MODEL_NAME =\"Mistral-Nemo-Instruct-2407-GGUF\"\n",
    "#MODEL_NAME = \"Phi-4-mini-instruct-GGUF\"\n",
    "MODEL_NAME =\"Qwen2-0.5B-Instruct-GGUF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_llm(observation):\n",
    "    \"\"\"Sends observation to the LLM and retrieves an action (0 or 1).\"\"\"\n",
    "    \n",
    "    instruction = \"\"\"\n",
    "    You are a reinforcement learning agent for the CartPole-v1 environment.\n",
    "\n",
    "    Your goal is to keep the pole balanced by choosing the correct action at each time step.\n",
    "\n",
    "    Each observation is a list of four numbers in this order:\n",
    "    1. Cart Position (x)\n",
    "    2. Cart Velocity (x_dot)\n",
    "    3. Pole Angle (theta)\n",
    "    4. Pole Angular Velocity (theta_dot)\n",
    "\n",
    "    Use these values to decide the best action to take:\n",
    "    - Action 0 = Move cart to the LEFT\n",
    "    - Action 1 = Move cart to the RIGHT\n",
    "\n",
    "    Respond with only the action number (0 or 1), and nothing else.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Observation: {observation}\n",
    "\n",
    "    Think step-by-step:\n",
    "    - Is the pole leaning left or right? (Check angle)\n",
    "    - Is it falling quickly or slowly? (Check angular velocity)\n",
    "    - Should we move the cart left or right to balance it?\n",
    "\n",
    "    Then respond with:\n",
    "    - 0 to move LEFT\n",
    "    - 1 to move RIGHT\n",
    "\n",
    "    Just respond with the action number.\n",
    "    \"\"\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": instruction},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 20,\n",
    "        \"stop\": [\"\\n\", \".\", \" \"]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(LLM_API_URL, headers={\"Content-Type\": \"application/json\"}, data=json.dumps(payload))\n",
    "        response_json = response.json()\n",
    "\n",
    "        raw_result = response_json.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\").strip()\n",
    "        action_token = raw_result.split()[0]  # Take first token if model outputs extra text\n",
    "\n",
    "        # Sanitize and interpret the result\n",
    "        action = 1 if action_token == \"1\" else 0  # Default to 0 unless it's exactly \"1\"\n",
    "\n",
    "        # Logging\n",
    "        print(f\"Observation: {observation}\")\n",
    "        print(f\"LLM Response: {action}\")\n",
    "\n",
    "        return action\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error processing LLM response:\", e)\n",
    "        return 0  # Default action in case of failure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cartpole():\n",
    "    \"\"\"Runs the CartPole-v1 environment with the LLM-based agent.\"\"\"\n",
    "    env = gym.make(\"CartPole-v1\", render_mode=\"human\")  # Change render_mode to 'None' if no visualization needed\n",
    "    EPISODES = 10  # Run multiple episodes\n",
    "    rewards = []\n",
    "    time_history = []\n",
    "\n",
    "    for episode in range(EPISODES):\n",
    "        observation, info = env.reset()\n",
    "        total_reward = 0\n",
    "        start_time = time.time()\n",
    "        for step in range(200):\n",
    "            action = query_llm(observation)\n",
    "            observation, reward, terminated, truncated, info = env.step(action)\n",
    "            total_reward += reward\n",
    "            if terminated or truncated:\n",
    "                end_time = time.time()\n",
    "                elapsed = end_time - start_time\n",
    "        \n",
    "                break\n",
    "        rewards.append(total_reward)\n",
    "        print(f\"Episode {episode+1}: Total Reward = {total_reward}\")\n",
    "    \n",
    "        time_history.append(elapsed)\n",
    "        print(f\" Elapsed Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "    # Close the environment after all episodes\n",
    "    env.close()\n",
    "    \n",
    "    print(\"Time History:\", time_history)\n",
    "    avg_time = sum(time_history) / len(time_history)\n",
    "    print(f\"\\nAverage Time over {EPISODES} episodes: {avg_time:.2f} seconds\")\n",
    "\n",
    "    \n",
    "    print(\"Reward History:\", rewards)\n",
    "    avg_reward = sum(rewards) / len(rewards)\n",
    "    print(f\"\\nAverage Reward over {EPISODES} episodes: {avg_reward}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Result Mistral-Nemo-Instruct-2407-GGUF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: [-0.01236809  0.04198546 -0.00319995 -0.02485636]\n",
      "LLM Response: 0\n",
      "Observation: [-0.01152838 -0.15309046 -0.00369708  0.26681522]\n",
      "LLM Response: 1\n",
      "Observation: [-0.01459019  0.04208406  0.00163922 -0.02703149]\n",
      "LLM Response: 1\n",
      "Observation: [-0.01374851  0.23718247  0.00109859 -0.3191968 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.00900486  0.04204489 -0.00528534 -0.0261676 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.00816396 -0.15300088 -0.00580869  0.26484308]\n",
      "LLM Response: 0\n",
      "Observation: [-1.1223977e-02 -3.4803945e-01 -5.1183254e-04  5.5568826e-01]\n",
      "LLM Response: 1\n",
      "Observation: [-0.01818477 -0.1529103   0.01060193  0.2628441 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.02124297 -0.34818196  0.01585881  0.558852  ]\n",
      "LLM Response: 1\n",
      "Observation: [-0.02820661 -0.15328617  0.02703585  0.2712074 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.03127233 -0.34878328  0.03246     0.57229346]\n",
      "LLM Response: 0\n",
      "Observation: [-0.038248   -0.54434496  0.04390587  0.87502307]\n",
      "LLM Response: 1\n",
      "Observation: [-0.0491349  -0.34984654  0.06140633  0.5964607 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.05613183 -0.54577166  0.07333555  0.90783656]\n",
      "LLM Response: 1\n",
      "Observation: [-0.06704726 -0.35171497  0.09149228  0.63907534]\n",
      "LLM Response: 1\n",
      "Observation: [-0.07408156 -0.15797977  0.10427379  0.37654918]\n",
      "LLM Response: 1\n",
      "Observation: [-0.07724116  0.03551857  0.11180477  0.11847914]\n",
      "LLM Response: 0\n",
      "Observation: [-0.07653078 -0.16101296  0.11417435  0.44423798]\n",
      "LLM Response: 1\n",
      "Observation: [-0.07975104  0.03232408  0.12305911  0.18961497]\n",
      "LLM Response: 1\n",
      "Observation: [-0.07910457  0.22549029  0.12685141 -0.06185506]\n",
      "LLM Response: 0\n",
      "Observation: [-0.07459476  0.02879938  0.12561432  0.2680051 ]\n",
      "LLM Response: 1\n",
      "Observation: [-0.07401877  0.2219257   0.13097441  0.01743169]\n",
      "LLM Response: 1\n",
      "Observation: [-0.06958026  0.41494983  0.13132304 -0.23122819]\n",
      "LLM Response: 0\n",
      "Observation: [-0.06128126  0.21821976  0.12669848  0.09982412]\n",
      "LLM Response: 0\n",
      "Observation: [-0.05691687  0.02153116  0.12869497  0.42964193]\n",
      "LLM Response: 1\n",
      "Observation: [-0.05648624  0.21461816  0.13728781  0.18013859]\n",
      "LLM Response: 1\n",
      "Observation: [-0.05219388  0.4075358   0.14089057 -0.06627912]\n",
      "LLM Response: 0\n",
      "Observation: [-0.04404316  0.2107045   0.13956499  0.26732725]\n",
      "LLM Response: 1\n",
      "Observation: [-0.03982907  0.40358734  0.14491154  0.02171521]\n",
      "LLM Response: 1\n",
      "Observation: [-0.03175732  0.5963659   0.14534584 -0.2219668 ]\n",
      "LLM Response: 1\n",
      "Observation: [-0.01983001  0.78914374  0.14090651 -0.46550307]\n",
      "LLM Response: 0\n",
      "Observation: [-0.00404713  0.5923413   0.13159645 -0.13193564]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.00779969  0.78535676  0.12895773 -0.3803777 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.02350683  0.58866197  0.12135018 -0.04997684]\n",
      "LLM Response: 0\n",
      "Observation: [0.03528007 0.39202785 0.12035064 0.27839476]\n",
      "LLM Response: 0\n",
      "Observation: [0.04312063 0.19541298 0.12591854 0.60648155]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.04702889 -0.00122381  0.13804817  0.9360238 ]\n",
      "LLM Response: 1\n",
      "Observation: [0.04700441 0.19179356 0.15676863 0.6897095 ]\n",
      "LLM Response: 1\n",
      "Observation: [0.05084028 0.38443273 0.17056283 0.45019564]\n",
      "LLM Response: 0\n",
      "Observation: [0.05852894 0.18736085 0.17956674 0.79141676]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.06227615 -0.00971223  0.19539508  1.1347827 ]\n",
      "LLM Response: 1\n",
      "Episode 1: Total Reward = 41.0\n",
      " Elapsed Time: 158.46 seconds\n",
      "Observation: [-0.02991529  0.0379254  -0.03106695  0.00858548]\n",
      "LLM Response: 0\n",
      "Observation: [-0.02915678 -0.15673755 -0.03089524  0.2913068 ]\n",
      "LLM Response: 1\n",
      "Observation: [-0.03229153  0.03881099 -0.0250691  -0.0109578 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.03151531 -0.15594263 -0.02528826  0.2737113 ]\n",
      "LLM Response: 1\n",
      "Observation: [-0.03463416  0.03953084 -0.01981403 -0.02683912]\n",
      "LLM Response: 1\n",
      "Observation: [-0.03384355  0.23493126 -0.02035082 -0.32570714]\n",
      "LLM Response: 1\n",
      "Observation: [-0.02914492  0.43033695 -0.02686496 -0.62473774]\n",
      "LLM Response: 0\n",
      "Observation: [-0.02053818  0.23560016 -0.03935971 -0.3406353 ]\n",
      "LLM Response: 1\n",
      "Observation: [-0.01582618  0.4312594  -0.04617242 -0.6454656 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.00720099  0.23681022 -0.05908173 -0.36767256]\n",
      "LLM Response: 0\n",
      "Observation: [-0.00246479  0.04257538 -0.06643519 -0.09418859]\n",
      "LLM Response: 1\n",
      "Observation: [-0.00161328  0.23858352 -0.06831896 -0.4070698 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.00315839  0.04449347 -0.07646035 -0.13668403]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.00404826  0.24062258 -0.07919403 -0.4524756 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.00886071  0.04670465 -0.08824354 -0.1857691 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.0097948  -0.14705119 -0.09195893  0.07782386]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.00685378 -0.34074277 -0.09040245  0.3401358 ]\n",
      "LLM Response: 1\n",
      "Observation: [ 3.8925842e-05 -1.4445861e-01 -8.3599731e-02  2.0369733e-02]\n",
      "LLM Response: 0\n",
      "Observation: [-0.00285025 -0.33828834 -0.08319234  0.28554922]\n",
      "LLM Response: 1\n",
      "Observation: [-0.00961601 -0.14208452 -0.07748135 -0.03216899]\n",
      "LLM Response: 1\n",
      "Observation: [-0.0124577   0.05405812 -0.07812473 -0.34825698]\n",
      "LLM Response: 1\n",
      "Observation: [-0.01137654  0.2501993  -0.08508988 -0.6645166 ]\n",
      "LLM Response: 1\n",
      "Observation: [-0.00637256  0.44639537 -0.09838021 -0.9827323 ]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.00255535  0.64268804 -0.11803485 -1.3046247 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.01540911  0.44924393 -0.14412734 -1.0510993 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.02439399  0.2562969  -0.16514933 -0.8069064 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.02951993  0.06377691 -0.18128747 -0.5703891 ]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.03079547  0.26091608 -0.19269525 -0.91425896]\n",
      "LLM Response: 1\n",
      "Episode 2: Total Reward = 28.0\n",
      " Elapsed Time: 107.68 seconds\n",
      "Observation: [-0.03306152 -0.01220718 -0.037337   -0.01123762]\n",
      "LLM Response: 1\n",
      "Observation: [-0.03330566  0.18342979 -0.03756175 -0.31546307]\n",
      "LLM Response: 0\n",
      "Observation: [-0.02963707 -0.01113755 -0.04387101 -0.03485849]\n",
      "LLM Response: 1\n",
      "Observation: [-0.02985982  0.18458517 -0.04456818 -0.34105402]\n",
      "LLM Response: 1\n",
      "Observation: [-0.02616812  0.38031197 -0.05138926 -0.6474514 ]\n",
      "LLM Response: 1\n",
      "Observation: [-0.01856188  0.5761108  -0.06433829 -0.9558637 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.00703966  0.38191044 -0.08345556 -0.6840683 ]\n",
      "LLM Response: 1\n",
      "Observation: [ 5.9854897e-04  5.7808590e-01 -9.7136930e-02 -1.0018148e+00]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.01216027  0.77436215 -0.11717322 -1.3233547 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.02764751  0.58089906 -0.14364032 -1.06952   ]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.03926549  0.77759814 -0.16503072 -1.4036152 ]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.05481745  0.97433984 -0.19310303 -1.7430172 ]\n",
      "LLM Response: 0\n",
      "Episode 3: Total Reward = 12.0\n",
      " Elapsed Time: 45.96 seconds\n",
      "Observation: [ 0.01172549  0.02803353 -0.00346549 -0.00209738]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.01228617 -0.16703855 -0.00350744  0.28949013]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.00894539 -0.36211032  0.00228236  0.58106476]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.00170319 -0.55726415  0.01390366  0.8744658 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.00944209 -0.75257236  0.03139298  1.1714873 ]\n",
      "LLM Response: 1\n",
      "Observation: [-0.02449354 -0.55787235  0.05482272  0.8888092 ]\n",
      "LLM Response: 1\n",
      "Observation: [-0.03565099 -0.36353552  0.0725989   0.6138518 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.0429217  -0.55959284  0.08487594  0.92848843]\n",
      "LLM Response: 1\n",
      "Observation: [-0.05411356 -0.36571294  0.10344571  0.66363907]\n",
      "LLM Response: 0\n",
      "Observation: [-0.06142782 -0.5621103   0.11671849  0.98701906]\n",
      "LLM Response: 1\n",
      "Observation: [-0.07267002 -0.3687283   0.13645887  0.7331571 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.08004459 -0.56544536  0.15112202  1.0654842 ]\n",
      "LLM Response: 1\n",
      "Observation: [-0.0913535  -0.37261093  0.17243169  0.82379013]\n",
      "LLM Response: 0\n",
      "Observation: [-0.09880571 -0.5696191   0.1889075   1.1653641 ]\n",
      "LLM Response: 1\n",
      "Episode 4: Total Reward = 14.0\n",
      " Elapsed Time: 53.56 seconds\n",
      "Observation: [ 0.04911596 -0.0291516   0.00589959 -0.04295266]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.04853293 -0.22435765  0.00504054  0.25158578]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.04404578 -0.02930804  0.01007225 -0.039503  ]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.04345962  0.16566804  0.0092822  -0.3289911 ]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.04677298  0.36065662  0.00270237 -0.61873245]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.05398611  0.5557407  -0.00967228 -0.91056305]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.06510092  0.75099224 -0.02788354 -1.2062702 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.08012076  0.55624145 -0.05200894 -0.9224543 ]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.0912456   0.7520261  -0.07045802 -1.2310178 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.10628612  0.5578776  -0.09507839 -0.9612152 ]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.11744367  0.7541399  -0.11430269 -1.28219   ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.13252647  0.5606442  -0.13994649 -1.0273722 ]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.14373936  0.75732344 -0.16049393 -1.3605169 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.15888582  0.56453556 -0.18770427 -1.1220344 ]\n",
      "LLM Response: 0\n",
      "Episode 5: Total Reward = 14.0\n",
      " Elapsed Time: 53.77 seconds\n",
      "Observation: [ 0.00243012 -0.02842784  0.00940791  0.00165075]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.00186156 -0.22368343  0.00944093  0.29728708]\n",
      "LLM Response: 1\n",
      "Observation: [-0.00261211 -0.02869733  0.01538667  0.00759654]\n",
      "LLM Response: 1\n",
      "Observation: [-0.00318605  0.16620061  0.0155386  -0.28019226]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.00013796 -0.02913951  0.00993476  0.01735071]\n",
      "LLM Response: 0\n",
      "Observation: [-0.00044483 -0.22440252  0.01028177  0.31315154]\n",
      "LLM Response: 0\n",
      "Observation: [-0.00493288 -0.41966942  0.0165448   0.6090592 ]\n",
      "LLM Response: 1\n",
      "Observation: [-0.01332627 -0.22478262  0.02872598  0.32163295]\n",
      "LLM Response: 1\n",
      "Observation: [-0.01782192 -0.03008127  0.03515864  0.03814569]\n",
      "LLM Response: 0\n",
      "Observation: [-0.01842355 -0.22568929  0.03592156  0.34171093]\n",
      "LLM Response: 1\n",
      "Observation: [-0.02293734 -0.03109634  0.04275578  0.06056845]\n",
      "LLM Response: 1\n",
      "Observation: [-0.02355926  0.16338733  0.04396714 -0.21832408]\n",
      "LLM Response: 0\n",
      "Observation: [-0.02029152 -0.03233465  0.03960066  0.08789735]\n",
      "LLM Response: 0\n",
      "Observation: [-0.02093821 -0.2280012   0.04135861  0.39280662]\n",
      "LLM Response: 0\n",
      "Observation: [-0.02549823 -0.42368492  0.04921474  0.6982371 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.03397193 -0.6194535   0.06317949  1.0059978 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.046361   -0.8153596   0.08329944  1.3178331 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.06266819 -1.0114304   0.1096561   1.6353812 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.0828968  -1.207655    0.14236373  1.9601244 ]\n",
      "LLM Response: 1\n",
      "Observation: [-0.1070499  -1.0143001   0.18156621  1.7147402 ]\n",
      "LLM Response: 1\n",
      "Episode 6: Total Reward = 20.0\n",
      " Elapsed Time: 76.97 seconds\n",
      "Observation: [ 0.00513339 -0.01021929  0.03204391 -0.02281432]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.004929   -0.20578578  0.03158762  0.2798041 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.00081328 -0.40134376  0.0371837   0.58228   ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.00721359 -0.5969664   0.0488293   0.8864406 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.01915292 -0.79271597  0.06655812  1.1940651 ]\n",
      "LLM Response: 1\n",
      "Observation: [-0.03500724 -0.5985161   0.09043942  0.9229639 ]\n",
      "LLM Response: 1\n",
      "Observation: [-0.04697756 -0.40472472  0.10889869  0.6600178 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.05507206 -0.60118014  0.12209905  0.9849083 ]\n",
      "LLM Response: 1\n",
      "Observation: [-0.06709566 -0.40788648  0.14179721  0.73293436]\n",
      "LLM Response: 0\n",
      "Observation: [-0.07525339 -0.60465324  0.1564559   1.066671  ]\n",
      "LLM Response: 1\n",
      "Observation: [-0.08734645 -0.4119081   0.17778933  0.82689536]\n",
      "LLM Response: 1\n",
      "Observation: [-0.09558462 -0.21960464  0.19432724  0.5949822 ]\n",
      "LLM Response: 1\n",
      "Error processing LLM response: list index out of range\n",
      "Episode 7: Total Reward = 13.0\n",
      " Elapsed Time: 49.62 seconds\n",
      "Observation: [-0.02495804  0.04123221 -0.00850201 -0.04615   ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.0241334  -0.1537668  -0.00942501  0.24383838]\n",
      "LLM Response: 1\n",
      "Observation: [-0.02720873  0.04148849 -0.00454824 -0.05180246]\n",
      "LLM Response: 1\n",
      "Observation: [-0.02637896  0.23667537 -0.00558429 -0.34591693]\n",
      "LLM Response: 1\n",
      "Error processing LLM response: list index out of range\n",
      "Observation: [-0.01300793  0.23693086 -0.02530974 -0.3516359 ]\n",
      "LLM Response: 1\n",
      "Observation: [-0.00826931  0.43240345 -0.03234246 -0.6521911 ]\n",
      "LLM Response: 1\n",
      "Observation: [ 3.7875629e-04  6.2796050e-01 -4.5386277e-02 -9.5488036e-01]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.01293797  0.82366264 -0.06448389 -1.2614702 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.02941122  0.6294219  -0.08971329 -0.9896598 ]\n",
      "LLM Response: 1\n",
      "Error processing LLM response: list index out of range\n",
      "Observation: [ 0.05851211  0.6320452  -0.13568884 -1.0526214 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.07115301  0.43895772 -0.15674128 -0.80542254]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.07993217  0.6358411  -0.17284973 -1.1430207 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.09264899  0.4433464  -0.19571014 -0.90914655]\n",
      "LLM Response: 1\n",
      "Episode 8: Total Reward = 15.0\n",
      " Elapsed Time: 57.10 seconds\n",
      "Observation: [-0.02513103 -0.04910458  0.03621456 -0.00933042]\n",
      "LLM Response: 1\n",
      "Observation: [-0.02611312  0.1454798   0.03602795 -0.29037085]\n",
      "LLM Response: 1\n",
      "Observation: [-0.02320353  0.34006998  0.03022053 -0.5714768 ]\n",
      "LLM Response: 1\n",
      "Observation: [-0.01640213  0.5347554   0.01879099 -0.85448813]\n",
      "LLM Response: 0\n",
      "Observation: [-0.00570702  0.33938247  0.00170123 -0.55595624]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.00108063  0.14423667 -0.00941789 -0.26273778]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.00396536 -0.05074959 -0.01467265  0.02695981]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.00295037 -0.24565808 -0.01413345  0.31497747]\n",
      "LLM Response: 1\n",
      "Observation: [-0.00196279 -0.05033769 -0.0078339   0.01787105]\n",
      "LLM Response: 0\n",
      "Observation: [-0.00296954 -0.24534641 -0.00747648  0.30807203]\n",
      "LLM Response: 1\n",
      "Observation: [-0.00787647 -0.05011874 -0.00131504  0.01304063]\n",
      "LLM Response: 1\n",
      "Observation: [-0.00887885  0.14502205 -0.00105423 -0.28005692]\n",
      "LLM Response: 1\n",
      "Observation: [-0.00597841  0.34015903 -0.00665537 -0.57307214]\n",
      "LLM Response: 1\n",
      "Observation: [ 8.247747e-04  5.353736e-01 -1.811681e-02 -8.678443e-01]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.01153225  0.7307374  -0.0354737  -1.1661679 ]\n",
      "LLM Response: 0\n",
      "Error processing LLM response: list index out of range\n",
      "Observation: [ 0.03686889  0.34181812 -0.07649334 -0.6111797 ]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.04370525  0.5379212  -0.08871693 -0.9269412 ]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.05446367  0.73412186 -0.10725576 -1.2461333 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.06914611  0.5405265  -0.13217843 -0.9888818 ]\n",
      "LLM Response: 0\n",
      "Error processing LLM response: list index out of range\n",
      "Observation: [ 0.0869046   0.15466398 -0.16676533 -0.4991971 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.08999788 -0.03776281 -0.17674927 -0.2633633 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.08924262 -0.22997946 -0.18201654 -0.03122446]\n",
      "LLM Response: 1\n",
      "Error processing LLM response: list index out of range\n",
      "Observation: [ 0.08398748 -0.22489905 -0.1901482  -0.1453681 ]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.07948951 -0.02763488 -0.19305557 -0.4914985 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.07893681 -0.21958463 -0.20288554 -0.26532918]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.07454512 -0.02223233 -0.20819212 -0.61452585]\n",
      "LLM Response: 0\n",
      "Episode 9: Total Reward = 29.0\n",
      " Elapsed Time: 111.19 seconds\n",
      "Observation: [ 0.0074821   0.02629201 -0.03275109 -0.01479688]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.00800794  0.22186798 -0.03304703 -0.3176306 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.0124453   0.02723192 -0.03939964 -0.03554998]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.01298994 -0.16730353 -0.04011064  0.24444625]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.00964387 -0.3618303  -0.03522171  0.52421236]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.00240726 -0.16623083 -0.02473747  0.22064206]\n",
      "LLM Response: 1\n",
      "Observation: [-0.00091736  0.02923582 -0.02032463 -0.07974029]\n",
      "LLM Response: 0\n",
      "Observation: [-0.00033264 -0.16558896 -0.02191943  0.2064615 ]\n",
      "LLM Response: 1\n",
      "Observation: [-0.00364442  0.02983947 -0.0177902  -0.09305452]\n",
      "LLM Response: 1\n",
      "Observation: [-0.00304763  0.22521183 -0.01965129 -0.3912967 ]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.00145661  0.4206071  -0.02747723 -0.69011015]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.00986875  0.22587699 -0.04127943 -0.40620252]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.01438629  0.03136396 -0.04940348 -0.12681425]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.01501357 -0.1630167  -0.05193976  0.1498823 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.01175323 -0.35735792 -0.04894212  0.42573756]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.00460607 -0.5517537  -0.04042737  0.7025988 ]\n",
      "LLM Response: 1\n",
      "Observation: [-0.006429   -0.35609543 -0.02637539  0.39746884]\n",
      "LLM Response: 0\n",
      "Observation: [-0.01355091 -0.55083346 -0.01842601  0.6817208 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.02456758 -0.74569476 -0.0047916   0.96854615]\n",
      "LLM Response: 0\n",
      "Observation: [-0.03948147 -0.940752    0.01457932  1.25972   ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.05829651 -1.1360574   0.03977372  1.5569332 ]\n",
      "LLM Response: 0\n",
      "Error processing LLM response: list index out of range\n",
      "Observation: [-0.10765031 -1.5274565   0.10814747  2.1755826 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.13819945 -1.7234519   0.15165913  2.4995916 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.17266849 -1.9194674   0.20165096  2.834657  ]\n",
      "LLM Response: 1\n",
      "Episode 10: Total Reward = 25.0\n",
      " Elapsed Time: 96.04 seconds\n",
      "Time History: [158.4616515636444, 107.67705082893372, 45.96321105957031, 53.561124324798584, 53.76915001869202, 76.96711874008179, 49.61942791938782, 57.104477405548096, 111.18616127967834, 96.04284906387329]\n",
      "\n",
      "Average Time over 10 episodes: 81.04 seconds\n",
      "Reward History: [41.0, 28.0, 12.0, 14.0, 14.0, 20.0, 13.0, 15.0, 29.0, 25.0]\n",
      "\n",
      "Average Reward over 10 episodes: 21.1\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_cartpole()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Phi-4-mini-instruct-GGUF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: [-0.01894447  0.02054997  0.01171449  0.00109933]\n",
      "LLM Response: 0\n",
      "Observation: [-0.01853347 -0.174738    0.01173647  0.2974552 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.02202823 -0.37002528  0.01768558  0.59381634]\n",
      "LLM Response: 0\n",
      "Observation: [-0.02942874 -0.5653903   0.02956191  0.8920173 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.04073654 -0.7609005   0.04740225  1.1938444 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.05595455 -0.95660317  0.07127914  1.5009998 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.07508662 -1.1525147   0.10129914  1.8150592 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.09813691 -1.3486078   0.13760032  2.1374218 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.12510906 -1.5447968   0.18034875  2.469251  ]\n",
      "LLM Response: 0\n",
      "Episode 1: Total Reward = 9.0\n",
      " Elapsed Time: 26.25 seconds\n",
      "Observation: [ 0.04190437 -0.00379333  0.03659861 -0.00890986]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.04182851 -0.19942053  0.03642041  0.29509202]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.0378401  -0.39504227  0.04232225  0.59903526]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.02993925 -0.59073     0.05430296  0.9047431 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.01812465 -0.78654367  0.07239781  1.2139878 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.00239378 -0.98252124  0.09667757  1.5284505 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.01725665 -1.1786673   0.12724659  1.8496747 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.04082999 -1.3749397   0.16424008  2.1790125 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.06832878 -1.5712336   0.20782033  2.517561  ]\n",
      "LLM Response: 1\n",
      "Episode 2: Total Reward = 9.0\n",
      " Elapsed Time: 26.98 seconds\n",
      "Observation: [ 0.02212219 -0.0126332  -0.03579123 -0.02513476]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.02186953 -0.20722409 -0.03629392  0.25604424]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.01772504 -0.40180954 -0.03117304  0.53706217]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.00968885 -0.59647965 -0.02043179  0.81976205]\n",
      "LLM Response: 0\n",
      "Observation: [-0.00224074 -0.7913161  -0.00403655  1.1059493 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.01806706 -0.98638475  0.01808243  1.3973631 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.03779476 -1.1817268   0.04602969  1.6956443 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.0614293  -1.3773487   0.07994258  2.002294  ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.08897627 -1.5732085   0.11998846  2.3186235 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.12044044 -1.7692014   0.16636093  2.6456914 ]\n",
      "LLM Response: 0\n",
      "Episode 3: Total Reward = 10.0\n",
      " Elapsed Time: 28.79 seconds\n",
      "Observation: [ 0.00367303  0.03948408 -0.00830945 -0.03105043]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.00446271  0.23472421 -0.00893046 -0.32634345]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.00915719  0.03973053 -0.01545733 -0.03649012]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.0099518  -0.15516639 -0.01618713  0.25127605]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.00684847 -0.3500535  -0.01116161  0.5388096 ]\n",
      "LLM Response: 0\n",
      "Observation: [-1.5259575e-04 -5.4501677e-01 -3.8541722e-04  8.2795489e-01]\n",
      "LLM Response: 0\n",
      "Observation: [-0.01105293 -0.74013346  0.01617368  1.1205165 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.0258556  -0.9354638   0.03858401  1.4182285 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.04456488 -1.1310415   0.06694859  1.7227178 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.06718571 -1.3268629   0.10140294  2.03546   ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.09372296 -1.522873    0.14211214  2.3577263 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.12418043 -1.7189498   0.18926667  2.690517  ]\n",
      "LLM Response: 0\n",
      "Episode 4: Total Reward = 12.0\n",
      " Elapsed Time: 35.41 seconds\n",
      "Observation: [ 0.0494367   0.04021766  0.01520832 -0.03144591]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.05024105 -0.15511905  0.0145794   0.26599634]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.04713867 -0.35044602  0.01989933  0.56324184]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.04012975 -0.54584146  0.03116416  0.862127  ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.02921292 -0.7413736   0.0484067   1.1644435 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.01438545 -0.9370911   0.07169557  1.471902  ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.00435637 -1.1330128   0.10113361  1.7860899 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.02701663 -1.3291148   0.13685541  2.1084225 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.05359893 -1.5253161   0.17902386  2.4400828 ]\n",
      "LLM Response: 0\n",
      "Episode 5: Total Reward = 9.0\n",
      " Elapsed Time: 26.11 seconds\n",
      "Observation: [-0.04096599 -0.01768412 -0.00381091  0.02403551]\n",
      "LLM Response: 0\n",
      "Observation: [-0.04131967 -0.21275121 -0.0033302   0.3155136 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.04557469 -0.40782556  0.00298008  0.6071445 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.05373121 -0.6029891   0.01512297  0.9007645 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.06579099 -0.7983126   0.03313826  1.1981623 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.08175724 -0.99384737  0.0571015   1.5010443 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.10163419 -1.1896143   0.08712239  1.8109949 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.12542647 -1.3855925   0.12334229  2.1294286 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.15313832 -1.581704    0.16593087  2.457532  ]\n",
      "LLM Response: 0\n",
      "Episode 6: Total Reward = 9.0\n",
      " Elapsed Time: 25.54 seconds\n",
      "Observation: [ 0.02156159  0.00399173 -0.00469451 -0.00083987]\n",
      "LLM Response: 1\n",
      "Observation: [ 0.02164143  0.19918069 -0.00471131 -0.29500026]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.02562504  0.00412622 -0.01061131 -0.00380693]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.02570757 -0.19084194 -0.01068745  0.2855092 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.02189073 -0.38580987 -0.00497727  0.57480234]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.01417453 -0.5808617   0.00651878  0.8659131 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.0025573  -0.7760717   0.02383704  1.1606385 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.01296414 -0.971496    0.04704981  1.460699  ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.03239406 -1.1671622   0.07626379  1.7677009 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.0557373  -1.3630581   0.11161781  2.0830905 ]\n",
      "LLM Response: 1\n",
      "Observation: [-0.08299846 -1.1692281   0.15327962  1.8269024 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.10638303 -1.3656818   0.18981767  2.1630158 ]\n",
      "LLM Response: 0\n",
      "Episode 7: Total Reward = 12.0\n",
      " Elapsed Time: 35.47 seconds\n",
      "Observation: [ 0.03565222  0.026758   -0.03473773 -0.04384235]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.03618738 -0.16784905 -0.03561457  0.23768128]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.0328304  -0.36244458 -0.03086095  0.518921  ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.02558151 -0.5571188  -0.02048253  0.8017216 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.01443913 -0.7519539  -0.0044481   1.0878916 ]\n",
      "LLM Response: 0\n",
      "Observation: [-5.9994770e-04 -9.4701695e-01  1.7309733e-02  1.3791754e+00]\n",
      "LLM Response: 0\n",
      "Observation: [-0.01954029 -1.1423507   0.04489324  1.677221  ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.0423873  -1.3379636   0.07843766  1.9835389 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.06914657 -1.533817    0.11810844  2.2994528 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.09982292 -1.7298102   0.1640975   2.6260376 ]\n",
      "LLM Response: 0\n",
      "Episode 8: Total Reward = 10.0\n",
      " Elapsed Time: 29.05 seconds\n",
      "Observation: [ 0.00495051 -0.04902197  0.00367411 -0.00971428]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.00397007 -0.24419641  0.00347983  0.2841256 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.00091386 -0.43936783  0.00916234  0.577904  ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.00970121 -0.634617    0.02072042  0.87345916]\n",
      "LLM Response: 0\n",
      "Observation: [-0.02239355 -0.83001447  0.0381896   1.1725838 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.03899384 -1.0256115   0.06164128  1.4769905 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.05950607 -1.2214297   0.09118108  1.7882711 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.08393466 -1.4174491   0.12694651  2.107849  ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.11228365 -1.6135933   0.16910349  2.4369197 ]\n",
      "LLM Response: 0\n",
      "Episode 9: Total Reward = 9.0\n",
      " Elapsed Time: 26.39 seconds\n",
      "Observation: [-0.02399665 -0.0179665  -0.02554985 -0.02965233]\n",
      "LLM Response: 0\n",
      "Observation: [-0.02435598 -0.21271291 -0.0261429   0.2548611 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.02861024 -0.40745202 -0.02104568  0.5391848 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.03675928 -0.6022719  -0.01026198  0.82516295]\n",
      "LLM Response: 0\n",
      "Observation: [-0.04880471 -0.797252    0.00624128  1.1146008 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.06474975 -0.99245536  0.02853329  1.409235  ]\n",
      "LLM Response: 1\n",
      "Observation: [-0.08459886 -0.7976987   0.05671799  1.1256065 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.10055283 -0.9935162   0.07923012  1.4355266 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.12042316 -1.1895207   0.10794066  1.7518804 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.14421357 -1.3856895   0.14297827  2.0760942 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.17192736 -1.5819434   0.18450014  2.4093635 ]\n",
      "LLM Response: 0\n",
      "Episode 10: Total Reward = 11.0\n",
      " Elapsed Time: 32.50 seconds\n",
      "Time History: [26.254230260849, 26.97865867614746, 28.787561893463135, 35.41403126716614, 26.10851740837097, 25.54452919960022, 35.4683256149292, 29.052656888961792, 26.391143798828125, 32.50262403488159]\n",
      "\n",
      "Average Time over 10 episodes: 29.25 seconds\n",
      "Reward History: [9.0, 9.0, 10.0, 12.0, 9.0, 9.0, 12.0, 10.0, 9.0, 11.0]\n",
      "\n",
      "Average Reward over 10 episodes: 10.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_cartpole()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Qwen2-0.5B-Instruct-GGUF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: [ 0.01479883 -0.00262138  0.04406992  0.02106171]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.0147464  -0.19834672  0.04449115  0.32731703]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.01077947 -0.39407292  0.05103749  0.6336919 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.00289801 -0.5898683   0.06371133  0.94200104]\n",
      "LLM Response: 0\n",
      "Observation: [-0.00889936 -0.78578824  0.08255135  1.2540032 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.02461512 -0.9818647   0.10763142  1.5713588 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.04425241 -1.1780939   0.13905859  1.8955818 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.06781429 -1.3744226   0.17697023  2.2279837 ]\n",
      "LLM Response: 0\n",
      "Episode 1: Total Reward = 8.0\n",
      " Elapsed Time: 24.93 seconds\n",
      "Observation: [ 0.02316907  0.0154818  -0.00691485  0.03421474]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.0234787  -0.17954032 -0.00623055  0.32470796]\n",
      "LLM Response: 0\n",
      "Observation: [ 1.9887896e-02 -3.7457299e-01  2.6360783e-04  6.1541957e-01]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.01239644 -0.56969863  0.012572    0.9081855 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 1.0024628e-03 -7.6498848e-01  3.0735709e-02  1.2047932e+00]\n",
      "LLM Response: 0\n",
      "Observation: [-0.01429731 -0.9604939   0.05483157  1.5069478 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.03350719 -1.1562363   0.08497053  1.8162323 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.05663191 -1.3521945   0.12129518  2.1340606 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.0836758  -1.5482913   0.16397639  2.461618  ]\n",
      "LLM Response: 0\n",
      "Episode 2: Total Reward = 9.0\n",
      " Elapsed Time: 27.17 seconds\n",
      "Observation: [ 0.02290128 -0.00679646  0.0271036   0.03429895]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.02276535 -0.20229639  0.02778958  0.33540863]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.01871942 -0.3978026   0.03449775  0.63672376]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.01076337 -0.5933882   0.04723223  0.940068  ]\n",
      "LLM Response: 0\n",
      "Observation: [-1.1043965e-03 -7.8911394e-01  6.6033587e-02  1.2472103e+00]\n",
      "LLM Response: 0\n",
      "Observation: [-0.01688668 -0.9850176   0.09097779  1.5598251 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.03658703 -1.181103    0.12217429  1.8794473 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.06020909 -1.3773265   0.15976325  2.2074187 ]\n",
      "LLM Response: 1\n",
      "Observation: [-0.08775562 -1.1840587   0.20391162  1.9679796 ]\n",
      "LLM Response: 0\n",
      "Episode 3: Total Reward = 9.0\n",
      " Elapsed Time: 27.19 seconds\n",
      "Observation: [-0.04615065 -0.02082948 -0.00223998  0.02257746]\n",
      "LLM Response: 0\n",
      "Observation: [-0.04656724 -0.21591924 -0.00178843  0.3145528 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.05088563 -0.41101566  0.00450262  0.60667115]\n",
      "LLM Response: 0\n",
      "Observation: [-0.05910594 -0.6062003   0.01663605  0.9007689 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.07122995 -0.80154365  0.03465142  1.1986341 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.08726082 -0.9970964   0.05862411  1.5019727 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.10720275 -1.1928791   0.08866356  1.8123678 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.13106033 -1.3888698   0.12491092  2.131232  ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.15883772 -1.5849897   0.16753556  2.4597483 ]\n",
      "LLM Response: 1\n",
      "Episode 4: Total Reward = 9.0\n",
      " Elapsed Time: 26.75 seconds\n",
      "Observation: [ 0.00799687  0.03556612 -0.01651457 -0.03093279]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.00870819 -0.15931515 -0.01713322  0.2564942 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.00552189 -0.35418835 -0.01200334  0.5437242 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.00156188 -0.54913956 -0.00112885  0.8326011 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.01254467 -0.74424607  0.01552317  1.1249287 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.0274296  -0.93956804  0.03802174  1.4224399 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.04622095 -1.135139    0.06647054  1.7267601 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.06892373 -1.330955    0.10100575  2.0393634 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.09554283 -1.5269607   0.14179301  2.3615189 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.12608205 -1.7230337   0.18902339  2.694224  ]\n",
      "LLM Response: 0\n",
      "Episode 5: Total Reward = 10.0\n",
      " Elapsed Time: 29.69 seconds\n",
      "Observation: [ 0.0447125  -0.04981106 -0.02227772  0.0411184 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.04371628 -0.24460658 -0.02145535  0.32669008]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.03882415 -0.43941662 -0.01492155  0.61253047]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.03003582 -0.6343269  -0.00267094  0.9004765 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.01734928 -0.8294125   0.01533859  1.1923187 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 7.6102832e-04 -1.0247298e+00  3.9184961e-02  1.4897696e+00]\n",
      "LLM Response: 0\n",
      "Observation: [-0.01973357 -1.2203064   0.06898035  1.7944266 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.04413969 -1.4161298   0.10486888  2.1077275 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.07246229 -1.612134    0.14702344  2.4308934 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.10470497 -1.8081818   0.1956413   2.7648618 ]\n",
      "LLM Response: 0\n",
      "Episode 6: Total Reward = 10.0\n",
      " Elapsed Time: 30.45 seconds\n",
      "Observation: [ 0.03081739 -0.00394231  0.0460068   0.045839  ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.03073855 -0.19969274  0.04692358  0.3526752 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.02674469 -0.39544946  0.05397708  0.6597775 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.0188357  -0.5912794   0.06717264  0.9689562 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.00701011 -0.78723574  0.08655176  1.2819617 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.0087346  -0.98334694  0.11219099  1.6004418 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.02840154 -1.1796046   0.14419983  1.9258926 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.05199363 -1.3759494   0.18271768  2.259601  ]\n",
      "LLM Response: 0\n",
      "Episode 7: Total Reward = 8.0\n",
      " Elapsed Time: 24.03 seconds\n",
      "Observation: [-0.02017744  0.00760133 -0.01762232  0.03458668]\n",
      "LLM Response: 0\n",
      "Observation: [-0.02002541 -0.18726353 -0.01693059  0.3216579 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.02377068 -0.38214034 -0.01049743  0.6089539 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.03141348 -0.577114    0.00168165  0.89831203]\n",
      "LLM Response: 0\n",
      "Observation: [-0.04295576 -0.7722587   0.01964789  1.1915231 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.05840094 -0.9676296   0.04347835  1.490299  ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.07775353 -1.1632531   0.07328433  1.7962356 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.10101859 -1.359115    0.10920904  2.1107662 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.12820089 -1.5551466   0.15142436  2.4351053 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.15930383 -1.7512081   0.20012647  2.7701812 ]\n",
      "LLM Response: 0\n",
      "Episode 8: Total Reward = 10.0\n",
      " Elapsed Time: 30.00 seconds\n",
      "Observation: [ 0.02380601  0.02344295 -0.00777146 -0.02331916]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.02427487 -0.1715667  -0.00823784  0.2669017 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.02084353 -0.36657012 -0.00289981  0.556975  ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.01351213 -0.56165123  0.00823969  0.8487429 ]\n",
      "LLM Response: 0\n",
      "Observation: [ 0.0022791  -0.7568846   0.02521455  1.1440054 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.01285859 -0.9523267   0.04809466  1.4444877 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.03190512 -1.1480064   0.07698441  1.7518022 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.05486525 -1.343913    0.11202046  2.0674028 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.08174351 -1.5399827   0.15336852  2.3925292 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.11254317 -1.7360818   0.2012191   2.728139  ]\n",
      "LLM Response: 0\n",
      "Episode 9: Total Reward = 10.0\n",
      " Elapsed Time: 29.86 seconds\n",
      "Observation: [-0.02850014  0.00109911 -0.04634022 -0.03266071]\n",
      "LLM Response: 0\n",
      "Observation: [-0.02847816 -0.19332872 -0.04699344  0.24504882]\n",
      "LLM Response: 0\n",
      "Observation: [-0.03234474 -0.38774908 -0.04209246  0.5225464 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.04009972 -0.5822541  -0.03164154  0.80167395]\n",
      "LLM Response: 0\n",
      "Observation: [-0.0517448  -0.7769281  -0.01560805  1.0842378 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.06728336 -0.9718407   0.0060767   1.3719825 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.08672018 -1.1670381   0.03351635  1.6665597 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.11006094 -1.3625336   0.06684754  1.96949   ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.13731161 -1.5582947   0.10623734  2.2821145 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.1684775  -1.7542287   0.15187964  2.6055336 ]\n",
      "LLM Response: 0\n",
      "Observation: [-0.20356208 -1.9501653   0.20399031  2.9405363 ]\n",
      "LLM Response: 0\n",
      "Episode 10: Total Reward = 11.0\n",
      " Elapsed Time: 32.70 seconds\n",
      "Time History: [24.931142807006836, 27.16780161857605, 27.194903135299683, 26.748417615890503, 29.693755388259888, 30.447845458984375, 24.02683997154236, 30.00247621536255, 29.859785556793213, 32.70393443107605]\n",
      "\n",
      "Average Time over 10 episodes: 28.28 seconds\n",
      "Reward History: [8.0, 9.0, 9.0, 9.0, 10.0, 10.0, 8.0, 10.0, 10.0, 11.0]\n",
      "\n",
      "Average Reward over 10 episodes: 9.4\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_cartpole()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
